{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23bb88b2",
   "metadata": {},
   "source": [
    "# 1. Common data problems\n",
    "\n",
    "In this chapter, you'll learn how to overcome some of the most common dirty data problems. You'll convert data types, apply range constraints to remove future data points, and remove duplicated data points to avoid double-counting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd8eaa",
   "metadata": {},
   "source": [
    "## 1.1 Data type constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a319e3",
   "metadata": {},
   "source": [
    "## 1.2 Common data types\n",
    "\n",
    "Manipulating and analyzing data with incorrect data types could lead to compromised analysis as you go along the data science workflow.\n",
    "\n",
    "When working with new data, you should always check the data types of your columns using the `.dtypes` attribute or the `.info()` method which you'll see in the next exercise. Often times, you'll run into columns that should be converted to different data types before starting any analysis.\n",
    "\n",
    "In this exercise, you'll first identify different types of data and correctly map them to their respective types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c5597",
   "metadata": {},
   "source": [
    "### 1.2.1 Instructions\n",
    "\n",
    "- Assign each card to what type of data you think it is.\n",
    "  \n",
    "  | Numeric data types                        | Text                           | Dates                   |\n",
    "  |:-----------------------------------------:|:------------------------------:|:-----------------------:|\n",
    "  | Number of items bought in a basket        | City of residence              | Order date of a product |\n",
    "  | Number of points on customer loyalty card | First name                     | Birthdates of clients   |\n",
    "  | Salary earned monthly                     | Shipping address of a customer |                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082b840",
   "metadata": {},
   "source": [
    "## 1.3 Numeric data or ... ?\n",
    "\n",
    "In this exercise, and throughout this chapter, you'll be working with bicycle ride sharing data in San Francisco called `ride_sharing`. It contains information on the start and end stations, the trip duration, and some user information for a bike sharing service.\n",
    "\n",
    "The `user_type` column contains information on whether a user is taking a free ride and takes on the following values:\n",
    "\n",
    "- `1` for free riders.\n",
    "- `2` for pay per ride.\n",
    "- `3` for monthly subscribers.\n",
    "\n",
    "In this instance, you will print the information of `ride_sharing` using `.info()` and see a firsthand example of how an incorrect data type can flaw your analysis of the dataset. The `pandas` package is imported as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe1ced",
   "metadata": {},
   "source": [
    "### 1.3.1 Instructions 1/3\n",
    "\n",
    "- Print the information of `ride_sharing`.\n",
    "- Use `.describe()` to print the summary statistics of the `user_type` column from `ride_sharing`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb832db",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print the information of ride_sharing\n",
    "print(ride_sharing.info())\n",
    "\n",
    "# Print summary statistics of user_type column\n",
    "print(ride_sharing['user_type'].describe())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b00f0",
   "metadata": {},
   "source": [
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 25760 entries, 0 to 25759\n",
    "Data columns (total 9 columns):\n",
    " #   Column           Non-Null Count  Dtype \n",
    "---  ------           --------------  ----- \n",
    " 0   duration         25760 non-null  object\n",
    " 1   station_A_id     25760 non-null  int64 \n",
    " 2   station_A_name   25760 non-null  object\n",
    " 3   station_B_id     25760 non-null  int64 \n",
    " 4   station_B_name   25760 non-null  object\n",
    " 5   bike_id          25760 non-null  int64 \n",
    " 6   user_type        25760 non-null  int64 \n",
    " 7   user_birth_year  25760 non-null  int64 \n",
    " 8   user_gender      25760 non-null  object\n",
    "dtypes: int64(5), object(4)\n",
    "memory usage: 2.0+ MB\n",
    "None\n",
    "count    25760.000\n",
    "mean         2.008\n",
    "std          0.705\n",
    "min          1.000\n",
    "25%          2.000\n",
    "50%          2.000\n",
    "75%          3.000\n",
    "max          3.000\n",
    "Name: user_type, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe064eeb",
   "metadata": {},
   "source": [
    "### 1.3.2 Instructions 2/3\n",
    "\n",
    "### Question\n",
    "\n",
    "By looking at the summary statistics - they don't really seem to offer much description on how users are distributed along their purchase type, why do you think that is?\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "- [ ] The `user_type` column is not of the correct type, it should be converted to `str`.\n",
    "\n",
    "- [ ] The `user_type` column has an infinity set of possible values, it should be converted to `category`.\n",
    "\n",
    "- [x] The `user_type` column has an finite set of possible values that represent groupings of data, it sholud be converted to `category`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65faf8",
   "metadata": {},
   "source": [
    "### 1.3.3 Instructions 3/3\n",
    "\n",
    "- Convert `user_type` into categorical by assigning it the `'category'` data type and store it in the `user_type_cat` column.\n",
    "- Make sure you converted `user_type_cat` correctly by using an `assert` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b4bc6",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print the information of ride_sharing\n",
    "print(ride_sharing.info())\n",
    "\n",
    "# Print summary statistics of user_type column\n",
    "print(ride_sharing['user_type'].describe())\n",
    "\n",
    "# Convert user_type from integer to category\n",
    "ride_sharing['user_type_cat'] = ride_sharing['user_type'].astype('category')\n",
    "\n",
    "# Write an assert statement confirming the change\n",
    "assert ride_sharing['user_type_cat'].dtype == 'category'\n",
    "\n",
    "# Print new summary statistics \n",
    "print(ride_sharing['user_type_cat'].describe())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424fd309",
   "metadata": {},
   "source": [
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 25760 entries, 0 to 25759\n",
    "Data columns (total 9 columns):\n",
    " #   Column           Non-Null Count  Dtype \n",
    "---  ------           --------------  ----- \n",
    " 0   duration         25760 non-null  object\n",
    " 1   station_A_id     25760 non-null  int64 \n",
    " 2   station_A_name   25760 non-null  object\n",
    " 3   station_B_id     25760 non-null  int64 \n",
    " 4   station_B_name   25760 non-null  object\n",
    " 5   bike_id          25760 non-null  int64 \n",
    " 6   user_type        25760 non-null  int64 \n",
    " 7   user_birth_year  25760 non-null  int64 \n",
    " 8   user_gender      25760 non-null  object\n",
    "dtypes: int64(5), object(4)\n",
    "memory usage: 2.0+ MB\n",
    "None\n",
    "count    25760.000\n",
    "mean         2.008\n",
    "std          0.705\n",
    "min          1.000\n",
    "25%          2.000\n",
    "50%          2.000\n",
    "75%          3.000\n",
    "max          3.000\n",
    "Name: user_type, dtype: float64\n",
    "count     25760\n",
    "unique        3\n",
    "top           2\n",
    "freq      12972\n",
    "Name: user_type_cat, dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c38196",
   "metadata": {},
   "source": [
    "## 1.4 Summing strings and concatenating numbers\n",
    "\n",
    "In the previous exercise, you were able to identify that `category` is the correct data type for `user_type` and convert it in order to extract relevant statistical summaries that shed light on the distribution of `user_type`.\n",
    "\n",
    "Another common data type problem is importing what should be numerical values as strings, as mathematical operations such as summing and multiplication lead to string concatenation, not numerical outputs.\n",
    "\n",
    "In this exercise, you'll be converting the string column `duration` to the type `int`. Before that however, you will need to make sure to strip `\"minutes\"` from the column in order to make sure `pandas` reads it as numerical. The `pandas` package has been imported as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541a887",
   "metadata": {},
   "source": [
    "### 1.4.1 Instructions\n",
    "\n",
    "- Use the `.strip()` method to strip `duration` of `\"minutes\"` and store it in the `duration_trim` column.\n",
    "- Convert `duration_trim` to `int` and store it in the `duration_time` column.\n",
    "- Write an `assert` statement that checks if `duration_time`'s **d**ata **type** is now an `int`.\n",
    "- Print the average ride duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca76d04",
   "metadata": {},
   "source": [
    "```python\n",
    "# Strip duration of minutes\n",
    "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip('minutes')\n",
    "\n",
    "# Convert duration to integer\n",
    "ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')\n",
    "\n",
    "# Write an assert statement making sure of conversion\n",
    "assert ride_sharing['duration_time'].dtype == 'int'\n",
    "\n",
    "# Print formed columns and calculate average ride duration \n",
    "print(ride_sharing[['duration','duration_trim','duration_time']])\n",
    "print(ride_sharing['duration_time'].mean())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a29a1d",
   "metadata": {},
   "source": [
    "```\n",
    "         duration duration_trim  duration_time\n",
    "0      12 minutes           12              12\n",
    "1      24 minutes           24              24\n",
    "2       8 minutes            8               8\n",
    "3       4 minutes            4               4\n",
    "4      11 minutes           11              11\n",
    "...           ...           ...            ...\n",
    "25755  11 minutes           11              11\n",
    "25756  10 minutes           10              10\n",
    "25757  14 minutes           14              14\n",
    "25758  14 minutes           14              14\n",
    "25759  29 minutes           29              29\n",
    "\n",
    "[25760 rows x 3 columns]\n",
    "11.389052795031056\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203236e5",
   "metadata": {},
   "source": [
    "## 1.5 Data range constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48d138",
   "metadata": {},
   "source": [
    "## 1.6 Tire size constraints\n",
    "\n",
    "In this lesson, you're going to build on top of the work you've been doing with the `ride_sharing` DataFrame. You'll be working with the `tire_sizes` column which contains data on each bike's tire size.\n",
    "\n",
    "Bicycle tire sizes could be either 26″, 27″ or 29″ and are here correctly stored as a categorical value. In an effort to cut maintenance costs, the ride sharing provider decided to set the maximum tire size to be 27″.\n",
    "\n",
    "In this exercise, you will make sure the `tire_sizes` column has the correct range by first converting it to an integer, then setting and testing the new upper limit of 27″ for tire sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c39ff",
   "metadata": {},
   "source": [
    "### 1.6.1 Instructions\n",
    "\n",
    "- Convert the `tire_sizes` column from `category` to `'int'`.\n",
    "- Use `.loc[]` to set all values of `tire_sizes` above 27 to 27.\n",
    "- Reconvert back `tire_sizes` to `'category'` from `int`.\n",
    "- Print the description of the `tire_sizes`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3597a64",
   "metadata": {},
   "source": [
    "```python\n",
    "# Convert tire_sizes to integer\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('int')\n",
    "\n",
    "# Set all values above 27 to 27\n",
    "ride_sharing.loc[ride_sharing['tire_sizes'] > 27, 'tire_sizes'] = 27\n",
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('category')\n",
    "\n",
    "# Print tire size description\n",
    "print(ride_sharing['tire_sizes'].describe())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c124d",
   "metadata": {},
   "source": [
    "```\n",
    "count     25760\n",
    "unique        2\n",
    "top          27\n",
    "freq      13274\n",
    "Name: tire_sizes, dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c7efe",
   "metadata": {},
   "source": [
    "## 1.7 Back to the future\n",
    "\n",
    "A new update to the data pipeline feeding into the `ride_sharing` DataFrame has been updated to register each ride's date. This information is stored in the `ride_date` column of the type `object`, which represents strings in `pandas`.\n",
    "\n",
    "A bug was discovered which was relaying rides taken today as taken next year. To fix this, you will find all instances of the `ride_date` column that occur anytime in the future, and set the maximum possible value of this column to today's date. Before doing so, you would need to convert `ride_date` to a `datetime` object.\n",
    "\n",
    "The `datetime` package has been imported as `dt`, alongside all the packages you've been using till now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051d60f",
   "metadata": {},
   "source": [
    "### 1.7.1 Instructions\n",
    "\n",
    "- Convert `ride_date` to a `datetime` object using `to_datetime()`, then convert the `datetime` object into a `date` and store it in `ride_dt` column.\n",
    "- Create the variable `today`, which stores today's date by using the `dt.date.today()` function.\n",
    "- For all instances of `ride_dt` in the future, set them to today's date.\n",
    "- Print the maximum date in the `ride_dt` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b1db5",
   "metadata": {},
   "source": [
    "```python\n",
    "# Convert ride_date to date\n",
    "ride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_date']).dt.date\n",
    "\n",
    "# Save today's date\n",
    "today = dt.date.today()\n",
    "\n",
    "# Set all in the future to today's date\n",
    "ride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n",
    "\n",
    "# Print maximum of ride_dt column\n",
    "print(ride_sharing['ride_dt'].max())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30923e",
   "metadata": {},
   "source": [
    "```\n",
    "2023-05-31\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1e54f",
   "metadata": {},
   "source": [
    "## 1.8 Uniqueness constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244fea1",
   "metadata": {},
   "source": [
    "## 1.9 How big is your subset?\n",
    "\n",
    "You have the following `loans` DataFrame which contains loan and credit score data for consumers, and some metadata such as their first and last names. You want to find both complete and incomplete duplicates using `.duplicated().`\n",
    "\n",
    "| first_name | last_name   | credit_score | has_loan |\n",
    "| ---------- | ----------- | ------------ | -------- |\n",
    "| Justin     | Saddlemeyer | 600          | 1        |\n",
    "| Hadrien    | Lacroix     | 450          | 0        |\n",
    "\n",
    "Choose the **correct** usage of `.duplicated()` below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380ef30",
   "metadata": {},
   "source": [
    "### 1.9.1 Answer the question\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "- [ ] `loans.duplicated()`  \n",
    "    Because the default method returns both complete and incomplete duplicates.\n",
    "\n",
    "- [ ] `loans.duplicated(subset = 'first_name')`  \n",
    "    Because constraining the duplicate rows to the first name lets me find incomplete duplicates as well.\n",
    "\n",
    "- [x] `loans.duplicated(subset = ['first_name', 'last_name'], keep = False)`  \n",
    "    Because subsetting on consumer metadata and not discarding any duplicate returns all duplicated rows.\n",
    "\n",
    "- [ ] `loans.duplicated(subset = ['first_name', 'last_name'], keep = 'first')`  Because this drops all duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f227d",
   "metadata": {},
   "source": [
    "## 1.10 Finding duplicates\n",
    "\n",
    "A new update to the data pipeline feeding into `ride_sharing` has added the `ride_id` column, which represents a unique identifier for each ride.\n",
    "\n",
    "The update however coincided with radically shorter average ride duration times and irregular user birth dates set in the future. Most importantly, the number of rides taken has increased by 20% overnight, leading you to think there might be both complete and incomplete duplicates in the `ride_sharing` DataFrame.\n",
    "\n",
    "In this exercise, you will confirm this suspicion by finding those duplicates. A sample of `ride_sharing` is in your environment, as well as all the packages you've been working with thus far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64677965",
   "metadata": {},
   "source": [
    "### 1.10.1 Instructions\n",
    "\n",
    "- Find duplicated rows of `ride_id` in the `ride_sharing` DataFrame while setting `keep` to `False`.\n",
    "- Subset `ride_sharing` on `duplicates` and sort by `ride_id` and assign the results to `duplicated_rides`.\n",
    "- Print the `ride_id`, `duration` and `user_birth_year` columns of `duplicated_rides` in that order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c8c0b",
   "metadata": {},
   "source": [
    "```python\n",
    "# Find duplicates\n",
    "duplicates = ride_sharing.duplicated(subset = 'ride_id', keep = False)\n",
    "\n",
    "# Sort your duplicated rides\n",
    "duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')\n",
    "\n",
    "# Print relevant columns of duplicated_rides\n",
    "print(duplicated_rides[['ride_id','duration','user_birth_year']])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d052a2e",
   "metadata": {},
   "source": [
    "```\n",
    "    ride_id  duration  user_birth_year\n",
    "22       33        10             1979\n",
    "39       33         2             1979\n",
    "53       55         9             1985\n",
    "65       55         9             1985\n",
    "74       71        11             1997\n",
    "75       71        11             1997\n",
    "76       89         9             1986\n",
    "77       89         9             2060\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6291f",
   "metadata": {},
   "source": [
    "## 1.11 Treating duplicates\n",
    "\n",
    "In the last exercise, you were able to verify that the new update feeding into `ride_sharing` contains a bug generating both complete and incomplete duplicated rows for some values of the `ride_id` column, with occasional discrepant values for the `user_birth_year` and `duration` columns.\n",
    "\n",
    "In this exercise, you will be treating those duplicated rows by first dropping complete duplicates, and then merging the incomplete duplicate rows into one while keeping the average `duration`, and the minimum `user_birth_year` for each set of incomplete duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2c434",
   "metadata": {},
   "source": [
    "### 1.11.1 Instructions\n",
    "\n",
    "- Drop complete duplicates in `ride_sharing` and store the results in `ride_dup`.\n",
    "- Create the `statistics` dictionary which holds **min**imum aggregation for `user_birth_year` and **mean** aggregation for `duration`.\n",
    "- Drop incomplete duplicates by grouping by `ride_id` and applying the aggregation in `statistics`.\n",
    "- Find duplicates again and run the `assert` statement to verify de-duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc68105",
   "metadata": {},
   "source": [
    "```python\n",
    "# Drop complete duplicates from ride_sharing\n",
    "ride_dup = ride_sharing.drop_duplicates()\n",
    "\n",
    "# Create statistics dictionary for aggregation function\n",
    "statistics = {'user_birth_year': 'min', 'duration': 'mean'}\n",
    "\n",
    "# Group by ride_id and compute new statistics\n",
    "ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n",
    "\n",
    "# Find duplicated values again\n",
    "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
    "duplicated_rides = ride_unique[duplicates == True]\n",
    "\n",
    "# Assert duplicates are processed\n",
    "assert duplicated_rides.shape[0] == 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f881750b",
   "metadata": {},
   "source": [
    "# 2. Text and categorical data problems\n",
    "\n",
    "Categorical and text data can often be some of the messiest parts of a dataset due to their unstructured nature. In this chapter, you’ll learn how to fix whitespace and capitalization inconsistencies in category labels, collapse multiple categories into one, and reformat strings for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92038476",
   "metadata": {},
   "source": [
    "## 2.1 Membership constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce7431",
   "metadata": {},
   "source": [
    "## 2.2 Members only\n",
    "\n",
    "Throughout the course so far, you've been exposed to some common problems that you may encounter with your data, from data type constraints, data range constrains, uniqueness constraints, and now membership constraints for categorical values.\n",
    "\n",
    "In this exercise, you will map hypothetical problems to their respective categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a99f9",
   "metadata": {},
   "source": [
    "### 2.2.1 Instructions\n",
    "\n",
    "- Map the data problem observed with the correct type of data problem.\n",
    "\n",
    "| Membership Constraint                                | Other Constraint                                    |\n",
    "|:----------------------------------------------------:|:---------------------------------------------------:|\n",
    "| A `GPA` column containing a `Z-` grade.              | A `birthdate` column with the values in the future. |\n",
    "| A `month` column with the value `14`.                | An `age` column with values above 130.              |\n",
    "| A `has_loan` column with the value `12`.             | A `revenue` column represented as a string.         |\n",
    "| A `day_of_week` column with the value `Suntermonday` |                                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf668f",
   "metadata": {},
   "source": [
    "## 2.3 Finding consistency\n",
    "\n",
    "In this exercise and throughout this chapter, you'll be working with the `airlines` DataFrame which contains survey responses on the San Francisco Airport from airline customers.\n",
    "\n",
    "The DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction. Another DataFrame named `categories` was created, containing all correct possible values for the survey columns.\n",
    "\n",
    "In this exercise, you will use both of these DataFrames to find survey answers with inconsistent values, and drop them, effectively performing an outer and inner join on both these DataFrames as seen in the video exercise. The `pandas` package has been imported as `pd`, and the `airlines` and `categories` DataFrames are in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3450fa",
   "metadata": {},
   "source": [
    "### 2.3.1 Instructions 1/4\n",
    "\n",
    "- Print the `categories` DataFrame and take a close look at all possible correct categories of the survey columns.\n",
    "- Print the unique values of the survey columns in `airlines` using the `.unique()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f3310",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print categories DataFrame\n",
    "print(categories)\n",
    "\n",
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9e8d0",
   "metadata": {},
   "source": [
    "```\n",
    "      cleanliness           safety          satisfaction\n",
    "0           Clean          Neutral        Very satisfied\n",
    "1         Average        Very safe               Neutral\n",
    "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
    "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
    "4           Dirty  Somewhat unsafe      Very unsatisfied\n",
    "Cleanliness:  ['Clean', 'Average', 'Unacceptable', 'Somewhat clean', 'Somewhat dirty', 'Dirty']\n",
    "Categories (6, object): ['Average', 'Clean', 'Dirty', 'Somewhat clean', 'Somewhat dirty', 'Unacceptable'] \n",
    "\n",
    "Safety:  ['Neutral', 'Very safe', 'Somewhat safe', 'Very unsafe', 'Somewhat unsafe']\n",
    "Categories (5, object): ['Neutral', 'Somewhat safe', 'Somewhat unsafe', 'Very safe', 'Very unsafe'] \n",
    "\n",
    "Satisfaction:  ['Very satisfied', 'Neutral', 'Somewhat satisfied', 'Somewhat unsatisfied', 'Very unsatisfied']\n",
    "Categories (5, object): ['Neutral', 'Somewhat satisfied', 'Somewhat unsatisfied', 'Very satisfied', 'Very unsatisfied'] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0384e",
   "metadata": {},
   "source": [
    "### 2.3.2 Instructions 2/4\n",
    "\n",
    "### Question\n",
    "\n",
    "Take a look at the output. Out of the `cleanliness`, `safety` and `satisfaction` columns, which one has an inconsistent category and what is it?\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "- [x] `cleanliness` because it has an `Unacceptable` category.\n",
    "\n",
    "- [ ] `cleanliness` because it has an `Terribly Dirty` category.\n",
    "\n",
    "- [ ] `satisfaction` because it has an `Very satisfied` category.\n",
    "\n",
    "- [ ] `safety` because it has a `Neutral` category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ccc2a",
   "metadata": {},
   "source": [
    "### 2.3.3 Instructions 3/4\n",
    "\n",
    "- Create a set out of the `cleanliness` column in `airlines` using `set()` and find the inconsistent category by finding the **difference** in the `cleanliness` column of `categories`.\n",
    "- Find rows of `airlines` with a `cleanliness` value not in `categories` and print the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff488c",
   "metadata": {},
   "source": [
    "```python\n",
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d30e50",
   "metadata": {},
   "source": [
    "```\n",
    "       id        day           airline  destination  dest_region dest_size boarding_area   dept_time  wait_min   cleanliness         safety        satisfaction\n",
    "4    2992  Wednesday          AMERICAN        MIAMI      East US       Hub   Gates 50-59  2018-12-31     559.0  Unacceptable      Very safe  Somewhat satisfied\n",
    "18   2913     Friday  TURKISH AIRLINES     ISTANBUL  Middle East       Hub  Gates 91-102  2018-12-31     225.0  Unacceptable      Very safe  Somewhat satisfied\n",
    "100  2321  Wednesday         SOUTHWEST  LOS ANGELES      West US       Hub   Gates 20-39  2018-12-31     130.0  Unacceptable  Somewhat safe  Somewhat satisfied\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465a6b5",
   "metadata": {},
   "source": [
    "### 2.3.4 Instructions 4/4\n",
    "\n",
    "- Print the rows with the consistent categories of `cleanliness` only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71382a2",
   "metadata": {},
   "source": [
    "```python\n",
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])\n",
    "\n",
    "# Print rows with consistent categories only\n",
    "print(airlines[~cat_clean_rows])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6df06",
   "metadata": {},
   "source": [
    "```\n",
    "       id        day           airline  destination  dest_region dest_size boarding_area   dept_time  wait_min   cleanliness         safety        satisfaction\n",
    "4    2992  Wednesday          AMERICAN        MIAMI      East US       Hub   Gates 50-59  2018-12-31     559.0  Unacceptable      Very safe  Somewhat satisfied\n",
    "18   2913     Friday  TURKISH AIRLINES     ISTANBUL  Middle East       Hub  Gates 91-102  2018-12-31     225.0  Unacceptable      Very safe  Somewhat satisfied\n",
    "100  2321  Wednesday         SOUTHWEST  LOS ANGELES      West US       Hub   Gates 20-39  2018-12-31     130.0  Unacceptable  Somewhat safe  Somewhat satisfied\n",
    "        id       day        airline        destination    dest_region dest_size boarding_area   dept_time  wait_min     cleanliness         safety        satisfaction\n",
    "0     1351   Tuesday    UNITED INTL             KANSAI           Asia       Hub  Gates 91-102  2018-12-31     115.0           Clean        Neutral      Very satisfied\n",
    "1      373    Friday         ALASKA  SAN JOSE DEL CABO  Canada/Mexico     Small   Gates 50-59  2018-12-31     135.0           Clean      Very safe      Very satisfied\n",
    "2     2820  Thursday          DELTA        LOS ANGELES        West US       Hub   Gates 40-48  2018-12-31      70.0         Average  Somewhat safe             Neutral\n",
    "3     1157   Tuesday      SOUTHWEST        LOS ANGELES        West US       Hub   Gates 20-39  2018-12-31     190.0           Clean      Very safe  Somewhat satisfied\n",
    "5      634  Thursday         ALASKA             NEWARK        East US       Hub   Gates 50-59  2018-12-31     140.0  Somewhat clean      Very safe      Very satisfied\n",
    "...    ...       ...            ...                ...            ...       ...           ...         ...       ...             ...            ...                 ...\n",
    "2804  1475   Tuesday         ALASKA       NEW YORK-JFK        East US       Hub   Gates 50-59  2018-12-31     280.0  Somewhat clean        Neutral  Somewhat satisfied\n",
    "2805  2222  Thursday      SOUTHWEST            PHOENIX        West US       Hub   Gates 20-39  2018-12-31     165.0           Clean      Very safe      Very satisfied\n",
    "2806  2684    Friday         UNITED            ORLANDO        East US       Hub   Gates 70-90  2018-12-31      92.0           Clean      Very safe      Very satisfied\n",
    "2807  2549   Tuesday        JETBLUE         LONG BEACH        West US     Small    Gates 1-12  2018-12-31      95.0           Clean  Somewhat safe      Very satisfied\n",
    "2808  2162  Saturday  CHINA EASTERN            QINGDAO           Asia     Large    Gates 1-12  2018-12-31     220.0           Clean      Very safe  Somewhat satisfied\n",
    "\n",
    "[2474 rows x 12 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caab96f",
   "metadata": {},
   "source": [
    "## 2.4 Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281943c",
   "metadata": {},
   "source": [
    "## 2.5 Categories of errors\n",
    "\n",
    "In the video exercise, you saw how to address common problems affecting categorical variables in your data, including white spaces and inconsistencies in your categories, and the problem of creating new categories and mapping existing ones to new ones.\n",
    "\n",
    "To get a better idea of the toolkit at your disposal, you will be mapping functions and methods from `pandas` and Python used to address each type of problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66865034",
   "metadata": {},
   "source": [
    "### 2.5.1 Instructions\n",
    "\n",
    "- Map each function/method to the categorical data problem it solves.\n",
    "\n",
    "| White spaces and inconsistancy | Creating or remapping categories |\n",
    "|:------------------------------:|:--------------------------------:|\n",
    "| `.str.lower()`                 | `pandas.qcut()`                  |\n",
    "| `.str.strip()`                 | `pandas.cut()`                   |\n",
    "| `.str.upper()`                 | `.replace()`                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dffc0b",
   "metadata": {},
   "source": [
    "## 2.6 Inconsistent categories\n",
    "\n",
    "In this exercise, you'll be revisiting the `airlines` DataFrame from the previous lesson.\n",
    "\n",
    "As a reminder, the DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction on the San Francisco Airport.\n",
    "\n",
    "In this exercise, you will examine two categorical columns from this DataFrame, `dest_region` and `dest_size` respectively, assess how to address them and make sure that they are cleaned and ready for analysis. The `pandas` package has been imported as `pd`, and the `airlines` DataFrame is in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4203a0dc",
   "metadata": {},
   "source": [
    "### 2.6.1 Instructions 1/4\n",
    "\n",
    "- Print the unique values in `dest_region` and `dest_size` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b7996",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a0973",
   "metadata": {},
   "source": [
    "```\n",
    "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
    " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
    " 'Australia/New Zealand' 'middle east']\n",
    "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
    " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0cbaa",
   "metadata": {},
   "source": [
    "### 2.6.2 Instructions 2/4\n",
    "\n",
    "### Question\n",
    "\n",
    "From looking at the output, what do you think is the problem with these columns?\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "The `dest_region` column has only inconsistent values due to capitalization.\n",
    "\n",
    "- [ ] The `dest_region` column has only inconsistent values due to capitalization\n",
    "\n",
    "- [ ] The `dest_region` column has only inconsistent values due to capitalization and has one value that needs to be remapped.\n",
    "\n",
    "- [ ] The `dest_size` column has only inconsistent values due to leading and trailing spaces.\n",
    "\n",
    "- [x] Both 2 and 3 are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676c8a7",
   "metadata": {},
   "source": [
    "### 2.6.3 Instructions 3/4\n",
    "\n",
    "- Change the capitalization of all values of `dest_region` to lowercase.\n",
    "- Replace the `'eur'` with `'europe'` in `dest_region` using the `.replace()` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f319b",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee713c6",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
    " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
    " 'Australia/New Zealand' 'middle east']\n",
    "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
    " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7503c",
   "metadata": {},
   "source": [
    "### 2.6.4 Instructions 4/4\n",
    "\n",
    "- Strip white spaces from the `dest_size` column using the `.strip()` method.\n",
    "- Verify that the changes have been into effect by printing the unique values of the columns using `.unique()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c320d",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f99231c",
   "metadata": {},
   "source": [
    "```\n",
    "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
    " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
    " 'Australia/New Zealand' 'middle east']\n",
    "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
    " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n",
    "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
    " 'europe' 'central/south america' 'australia/new zealand']\n",
    "['Hub' 'Small' 'Medium' 'Large']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd709e4",
   "metadata": {},
   "source": [
    "## 2.7 Remapping categories\n",
    "\n",
    "To better understand survey respondents from `airlines`, you want to find out if there is a relationship between certain responses and the day of the week and wait time at the gate.\n",
    "\n",
    "The `airlines` DataFrame contains the `day` and `wait_min` columns, which are categorical and numerical respectively. The `day` column contains the exact day a flight took place, and `wait_min` contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:\n",
    "\n",
    "- `wait_type`: `'short'` for 0-60 min, `'medium'` for 60-180 and `long` for 180+\n",
    "- `day_week`: `'weekday'` if day is in the weekday, `'weekend'` if day is in the weekend.\n",
    "\n",
    "The `pandas` and `numpy` packages have been imported as `pd` and `np`. Let's create some new categorical data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d736c",
   "metadata": {},
   "source": [
    "### 2.7.1 Instructions\n",
    "\n",
    "- Create the ranges and labels for the `wait_type` column mentioned in the description.\n",
    "- Create the `wait_type` column by from `wait_min` by using `pd.cut()`, while inputting `label_ranges` and `label_names` in the correct arguments.\n",
    "- Create the `mapping` dictionary mapping weekdays to `'weekday'` and weekend days to `'weekend'`.\n",
    "- Create the `day_week` column by using `.replace()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78e4f0",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ad01f",
   "metadata": {},
   "source": [
    "## 2.8 Cleaning text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273d61d",
   "metadata": {},
   "source": [
    "## 2.9 Removing titles and taking names\n",
    "\n",
    "While collecting survey respondent metadata in the `airlines` DataFrame, the full name of respondents was saved in the `full_name` column. However upon closer inspection, you found that a lot of the different names are prefixed by honorifics such as `\"Dr.\"`, `\"Mr.\"`, `\"Ms.\"` and `\"Miss\"`.\n",
    "\n",
    "Your ultimate objective is to create two new columns named `first_name` and `last_name`, containing the first and last names of respondents respectively. Before doing so however, you need to remove honorifics.\n",
    "\n",
    "The `airlines` DataFrame is in your environment, alongside `pandas` as `pd.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f037de",
   "metadata": {},
   "source": [
    "### 2.9.1 Instructions\n",
    "\n",
    "- Remove `\"Dr.\"`, `\"Mr.\"`, `\"Miss\"` and `\"Ms.\"` from `full_name` by replacing them with an empty string `\"\"` in that order.\n",
    "- Run the `assert` statement using `.str.contains()` that tests whether `full_name` still contains any of the honorifics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a25b65",
   "metadata": {},
   "source": [
    "```python\n",
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\")\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb9cd3b",
   "metadata": {},
   "source": [
    "## 2.10 Keeping it descriptive\n",
    "\n",
    "To further understand travelers' experiences in the San Francisco Airport, the quality assurance department sent out a qualitative questionnaire to all travelers who gave the airport the worst score on all possible categories. The objective behind this questionnaire is to identify common patterns in what travelers are saying about the airport.\n",
    "\n",
    "Their response is stored in the `survey_response` column. Upon a closer look, you realized a few of the answers gave the shortest possible character amount without much substance. In this exercise, you will isolate the responses with a character count higher than ***40*** , and make sure your new DataFrame contains responses with ***40*** characters or more using an `assert` statement.\n",
    "\n",
    "The `airlines` DataFrame is in your environment, and `pandas` is imported as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556650d",
   "metadata": {},
   "source": [
    "### 2.10.1 Instructions\n",
    "\n",
    "- Using the `airlines` DataFrame, store the length of each instance in the `survey_response` column in `resp_length` by using `.str.len()`.\n",
    "- Isolate the rows of `airlines` with `resp_length` higher than `40`.\n",
    "- Assert that the smallest `survey_response` length in `airlines_survey` is now bigger than `40`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d054ad",
   "metadata": {},
   "source": [
    "```python\n",
    "# Store length of each row in survey_response column\n",
    "resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey['survey_response'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05208a7",
   "metadata": {},
   "source": [
    "```\n",
    "18    The airport personnell forgot to alert us of d...\n",
    "19    The food in the airport was really really expe...\n",
    "20    One of the other travelers was really loud and...\n",
    "21    I don't remember answering the survey with the...\n",
    "22    The airport personnel kept ignoring my request...\n",
    "23    The chair I sat in was extremely uncomfortable...\n",
    "24    I wish you were more like other airports, the ...\n",
    "25    I was really unsatisfied with the wait times b...\n",
    "27    The flight was okay, but I didn't really like ...\n",
    "28    We were really slowed down by security measure...\n",
    "29    There was a spill on the aisle next to the bat...\n",
    "30    I felt very unsatisfied by how long the flight...\n",
    "Name: survey_response, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7406963",
   "metadata": {},
   "source": [
    "# 3 Advanced data problems\n",
    "\n",
    "In this chapter, you’ll dive into more advanced data cleaning problems, such as ensuring that weights are all written in kilograms instead of pounds. You’ll also gain invaluable skills that will help you verify that values have been added correctly and that missing values don’t negatively impact your analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a23cb",
   "metadata": {},
   "source": [
    "## 3.1 Uniformity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84561f",
   "metadata": {},
   "source": [
    "## 3.2 Ambiguous dates\n",
    "\n",
    "You have a DataFrame containing a `subscription_date` column that was collected from various sources with different Date formats such as `YYYY-mm-dd` and `YYYY-dd-mm`. What is the best way to unify the formats for ambiguous values such as `2019-04-07`?\n",
    "\n",
    "### 3.2.1 Answer the question\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "- [ ] Set them to `NA` and drop them.\n",
    "\n",
    "- [ ] Infer the format of the data in question by checking the format of subsequent and previous values.\n",
    "\n",
    "- [ ] Infer the format from the original data source.\n",
    "\n",
    "- [x] All of the above are possible, as long as we investigate where our data comes from, and understand the dynamics affecting it before cleaning it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17666e5",
   "metadata": {},
   "source": [
    "## 3.3 Uniform currencies\n",
    "\n",
    "In this exercise and throughout this chapter, you will be working with a retail banking dataset stored in the `banking` DataFrame. The dataset contains data on the amount of money stored in accounts (`acct_amount`), their currency (`acct_cur`), amount invested (`inv_amount`), account opening date (`account_opened`), and last transaction date (`last_transaction`) that were consolidated from American and European branches.\n",
    "\n",
    "You are tasked with understanding the average account size and how investments vary by the size of account, however in order to produce this analysis accurately, you first need to unify the currency amount into dollars. The `pandas` package has been imported as `pd`, and the `banking` DataFrame is in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b5537",
   "metadata": {},
   "source": [
    "### 3.3.1 Instructions\n",
    "\n",
    "- Find the rows of `acct_cur` in `banking` that are equal to `'euro'` and store them in the variable `acct_eu`.\n",
    "- Find all the rows of `acct_amount` in `banking` that fit the `acct_eu` condition, and convert them to USD by multiplying them with `1.1`.\n",
    "- Find all the rows of `acct_cur` in `banking` that fit the `acct_eu` condition, set them to `'dollar'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8913a",
   "metadata": {},
   "source": [
    "```python\n",
    "# Find values of acct_cur that are equal to 'euro'\n",
    "acct_eu = banking['acct_cur'] == 'euro'\n",
    "\n",
    "# Convert acct_amount where it is in euro to dollars\n",
    "banking.loc[acct_eu, 'acct_amount'] = banking.loc[acct_eu, 'acct_amount'] * 1.1\n",
    "\n",
    "# Unify acct_cur column by changing 'euro' values to 'dollar'\n",
    "banking.loc[acct_eu, 'acct_cur'] = 'dollar'\n",
    "\n",
    "# Assert that only dollar currency remains\n",
    "assert banking['acct_cur'].unique() == 'dollar'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810d79e",
   "metadata": {},
   "source": [
    "## 3.4 Uniform dates\n",
    "\n",
    "After having unified the currencies of your different account amounts, you want to add a temporal dimension to your analysis and see how customers have been investing their money given the size of their account over each year. The `account_opened` column represents when customers opened their accounts and is a good proxy for segmenting customer activity and investment over time.\n",
    "\n",
    "However, since this data was consolidated from multiple sources, you need to make sure that all dates are of the same format. You will do so by converting this column into a `datetime` object, while making sure that the format is inferred and potentially incorrect formats are set to missing. The `banking` DataFrame is in your environment and `pandas` was imported as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb354360",
   "metadata": {},
   "source": [
    "### 3.4.1 Instructions 1/4\n",
    "\n",
    "- Print the header of `account_opened` from the `banking` DataFrame and take a look at the different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947431ef",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print the header of account_opened\n",
    "print(banking['account_opened'].head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac1682",
   "metadata": {},
   "source": [
    "```\n",
    "0          2018-03-05\n",
    "1            21-01-18\n",
    "2    January 26, 2018\n",
    "3            21-14-17\n",
    "4            05-06-17\n",
    "Name: account_opened, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa051da",
   "metadata": {},
   "source": [
    "### 3.4.2 Instructions 2/4\n",
    "\n",
    "### Question\n",
    "\n",
    "Take a look at the output. You tried converting the values to `datetime` using the default `to_datetime()` function without changing any argument, however received the following error:\n",
    "\n",
    "```\n",
    "ValueError: month must be in 1..12\n",
    "```\n",
    "\n",
    "Why do you think that is?\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "- [ ] The `to_datetime()` function needs to be explicity told which date format each row is in.\n",
    "\n",
    "- [ ] The `to_datetime()` function can only be applied on `YY-mm-dd` date formats.\n",
    "\n",
    "- [x] The `21-14-17` entry is erroneous and leads to an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d7a92",
   "metadata": {},
   "source": [
    "### 3.4.3 Instructions 3/4\n",
    "\n",
    "- Convert the `account_opened` column to `datetime`, while making sure the date format is inferred and that erroneous formats that raise error return a missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9d2a6",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print the header of account_opened\n",
    "print(banking['account_opened'].head())\n",
    "\n",
    "# Convert account_opened to datetime\n",
    "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
    "                                           # Infer datetime format\n",
    "                                           infer_datetime_format = True,\n",
    "                                           # Return missing value for error\n",
    "                                           errors = 'coerce') \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec3138",
   "metadata": {},
   "source": [
    "```\n",
    "0          2018-03-05\n",
    "1            21-01-18\n",
    "2    January 26, 2018\n",
    "3            21-14-17\n",
    "4            05-06-17\n",
    "Name: account_opened, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31388d37",
   "metadata": {},
   "source": [
    "### 3.4.4 Instructions 4/4\n",
    "\n",
    "- Extract the year from the amended `account_opened` column and assign it to the `acct_year` column.\n",
    "- Print the newly created `acct_year` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817aaf0",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print the header of account_opend\n",
    "print(banking['account_opened'].head())\n",
    "\n",
    "# Convert account_opened to datetime\n",
    "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
    "                                           # Infer datetime format\n",
    "                                           infer_datetime_format = True,\n",
    "                                           # Return missing value for error\n",
    "                                           errors = 'coerce') \n",
    "\n",
    "# Get year of account opened\n",
    "banking['acct_year'] = banking['account_opened'].dt.strftime('%Y')\n",
    "\n",
    "# Print acct_year\n",
    "print(banking['acct_year'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2291ca",
   "metadata": {},
   "source": [
    "```\n",
    "0          2018-03-05\n",
    "1            21-01-18\n",
    "2    January 26, 2018\n",
    "3            21-14-17\n",
    "4            05-06-17\n",
    "Name: account_opened, dtype: object\n",
    "0     2018\n",
    "1     2018\n",
    "2     2018\n",
    "3      NaN\n",
    "4     2017\n",
    "      ... \n",
    "92    2017\n",
    "93    2018\n",
    "94    2018\n",
    "95    2017\n",
    "96    2017\n",
    "Name: acct_year, Length: 97, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ae91f",
   "metadata": {},
   "source": [
    "## 3.5 Cross field validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e2fedb",
   "metadata": {},
   "source": [
    "## 3.6 Cross field or no cross field?\n",
    "\n",
    "Throughout this course, you've been immersed in a variety of data cleaning problems from range constraints, data type constraints, uniformity and more.\n",
    "\n",
    "In this lesson, you were introduced to cross field validation as a means to sanity check your data and making sure you have strong data integrity.\n",
    "\n",
    "Now, you will map different applicable concepts and techniques to their respective categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611d0e3",
   "metadata": {},
   "source": [
    "### 3.6.1 Instructions\n",
    "\n",
    "- Map different applicable concepts and techniques to their respective categories.\n",
    "\n",
    "| Cross field validation                                                  | Not cross field validation                                                |\n",
    "|:-----------------------------------------------------------------------:|:-------------------------------------------------------------------------:|\n",
    "| Confirming the Age provided by users by cross checking their birthdays. | Making sure a `subscription_date` column has no values set in the future. |\n",
    "| Row wise operations such as `.sum(axis = 1)`                            | The use of the `.astype()` method.                                        |\n",
    "|                                                                         | Making sure that a `revenue` column is a numeric column.                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff9408c",
   "metadata": {},
   "source": [
    "## 3.7 How's our data integrity?\n",
    "\n",
    "New data has been merged into the `banking` DataFrame that contains details on how investments in the `inv_amount` column are allocated across four different funds A, B, C and D.\n",
    "\n",
    "Furthermore, the age and birthdays of customers are now stored in the `age` and `birth_date` columns respectively.\n",
    "\n",
    "You want to understand how customers of different age groups invest. However, you want to first make sure the data you're analyzing is correct. You will do so by cross field checking values of `inv_amount` and `age` against the amount invested in different funds and customers' birthdays. Both `pandas` and `datetime` have been imported as `pd` and `dt` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ad9821",
   "metadata": {},
   "source": [
    "### 3.7.1 Instructions 1/2\n",
    "\n",
    "- Find the rows where the sum of all rows of the `fund_columns` in `banking` are equal to the `inv_amount` column.\n",
    "- Store the values of `banking` with consistent `inv_amount` in `consistent_inv`, and those with inconsistent ones in `inconsistent_inv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da4b56",
   "metadata": {},
   "source": [
    "```python\n",
    "# Store fund columns to sum against\n",
    "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']\n",
    "\n",
    "# Find rows where fund_columns row sum == inv_amount\n",
    "inv_equ = banking[fund_columns].sum(axis = 1) == banking['inv_amount']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_inv = banking[inv_equ]\n",
    "inconsistent_inv = banking[~inv_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd90b33",
   "metadata": {},
   "source": [
    "```\n",
    "Number of inconsistent investments:  8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8deee03",
   "metadata": {},
   "source": [
    "### 3.7.2 Instructions 2/2\n",
    "\n",
    "- Store today's date into `today`, and manually calculate customers' ages and store them in `ages_manual`.\n",
    "\n",
    "- Find all rows of `banking` where the `age` column is equal to `ages_manual` and then filter `banking` into `consistent_ages` and `inconsistent_ages`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34367404",
   "metadata": {},
   "source": [
    "```python\n",
    "# Store today's date and find ages\n",
    "today = dt.date.today()\n",
    "ages_manual = today.year - banking['birth_date'].dt.year\n",
    "\n",
    "# Find rows where age column == ages_manual\n",
    "age_equ = ages_manual == banking['age']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_ages = banking[age_equ]\n",
    "inconsistent_ages = banking[~age_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent ages: \", inconsistent_ages.shape[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e59676",
   "metadata": {},
   "source": [
    "```\n",
    "Number of inconsistent ages:  4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39f894",
   "metadata": {},
   "source": [
    "## 3.8 Completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee8479",
   "metadata": {},
   "source": [
    "## 3.9 Is this missing at random?\n",
    "\n",
    "You've seen in the video exercise how there are a variety of missingness types when observing missing data. As a reminder, missingness types can be described as the following:\n",
    "\n",
    "- **Missing Completely at Random:** No systematic relationship between a column's missing values and other or own values.*\n",
    "- **Missing at Random:** There is a systematic relationship between a column's missing values and other **observed** values.*\n",
    "- **Missing not at Random:** There is a systematic relationship between a column's missing values and **unobserved** values.*\n",
    "\n",
    "You have a DataFrame containing customer satisfaction scores for a service. What type of missingness is the following?  \n",
    "\n",
    " *A customer* `satisfaction_score` *column with missing values for highly dissatisfied customers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929548a",
   "metadata": {},
   "source": [
    "### 3.9.1 Answer the question\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "- [ ] Missing completely at random.\n",
    "\n",
    "- [ ] Missing at random.\n",
    "\n",
    "- [x] Missing not at random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085e8f9",
   "metadata": {},
   "source": [
    "## 3.10 Missing investors\n",
    "\n",
    "Dealing with missing data is one of the most common tasks in data science. There are a variety of types of missingness, as well as a variety of types of solutions to missing data.\n",
    "\n",
    "You just received a new version of the `banking` DataFrame containing data on the amount held and invested for new and existing customers. However, there are rows with missing `inv_amount` values.\n",
    "\n",
    "You know for a fact that most customers below 25 do not have investment accounts yet, and suspect it could be driving the missingness. The `pandas`, `missingno` and `matplotlib.pyplot` packages have been imported as `pd`, `msno` and `plt` respectively. The `banking` DataFrame is in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10240b4",
   "metadata": {},
   "source": [
    "### 3.10.1 Instructions 1/4\n",
    "\n",
    "- Print the number of missing values by column in the `banking` DataFrame.\n",
    "- Plot and show the missingness matrix of `banking` with the `msno.matrix()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53182ab2",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print number of missing values in banking\n",
    "print(banking.isna().sum())\n",
    "\n",
    "# Visualize missingness matrix\n",
    "msno.matrix(banking)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fde4c8",
   "metadata": {},
   "source": [
    "```\n",
    "cust_id              0\n",
    "age                  0\n",
    "acct_amount          0\n",
    "inv_amount          13\n",
    "account_opened       0\n",
    "last_transaction     0\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "attachments": {
    "1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "050fe288",
   "metadata": {},
   "source": [
    "![1.png](attachment:1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be1c63",
   "metadata": {},
   "source": [
    "### 3.10.2 Instructions 2/4\n",
    "\n",
    "- Isolate the values of `banking` missing values of `inv_amount` into `missing_investors` and with non-missing `inv_amount` values into `investors`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec6fcab",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print number of missing values in banking\n",
    "print(banking.isna().sum())\n",
    "\n",
    "# Visualize missingness matrix\n",
    "msno.matrix(banking)\n",
    "plt.show()\n",
    "\n",
    "# Isolate missing and non missing values of inv_amount\n",
    "missing_investors = banking[banking['inv_amount'].isna()]\n",
    "investors = banking[~banking['inv_amount'].isna()]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b791b",
   "metadata": {},
   "source": [
    "### 3.10.3 Instructions 3/4\n",
    "\n",
    "### Question\n",
    "\n",
    "Now that you've isolated `banking` into `investors` and `missing_investors`, use the `.describe()` method on both of these DataFrames in the IPython shell to understand whether there are structural differences between them. What do you think is going on?\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "- [ ] The data is missing completely at random and there are no drivers behind the missingness.\n",
    "\n",
    "- [x] The `inv_amount` is missing only for young customers, since the average age in `missing_investors` is 22 and the maximum age is 25.\n",
    "\n",
    "- [ ] The `inv_amount` is missing only for old customers, since the average age in `missing_investors` is 42 and the maximum age is 59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbd0c1",
   "metadata": {},
   "source": [
    "### 3.10.4 Instructions 4/4\n",
    "\n",
    "- Sort the `banking` DataFrame by the `age` column and plot the missingness matrix of `banking_sorted`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6231584c",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print number of missing values in banking\n",
    "print(banking.isna().sum())\n",
    "\n",
    "# Visualize missingness matrix\n",
    "msno.matrix(banking)\n",
    "plt.show()\n",
    "\n",
    "# Isolate missing and non missing values of inv_amount\n",
    "missing_investors = banking[banking['inv_amount'].isna()]\n",
    "investors = banking[~banking['inv_amount'].isna()]\n",
    "\n",
    "# Sort banking by age and visualize\n",
    "banking_sorted = banking.sort_values(['age'])\n",
    "msno.matrix(banking_sorted)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412430c",
   "metadata": {},
   "source": [
    "```\n",
    "cust_id              0\n",
    "age                  0\n",
    "acct_amount          0\n",
    "inv_amount          13\n",
    "account_opened       0\n",
    "last_transaction     0\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "attachments": {
    "2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3a8680ce",
   "metadata": {},
   "source": [
    "![2.png](attachment:2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab87bbd",
   "metadata": {},
   "source": [
    "## 3.11 Follow the money\n",
    "\n",
    "In this exercise, you're working with another version of the `banking` DataFrame that contains missing values for both the `cust_id` column and the `acct_amount` column.\n",
    "\n",
    "You want to produce analysis on how many unique customers the bank has, the average amount held by customers and more. You know that rows with missing `cust_id` don't really help you, and that on average `acct_amount` is usually 5 times the amount of `inv_amount`.\n",
    "\n",
    "In this exercise, you will drop rows of `banking` with missing `cust_id`s, and impute missing values of `acct_amount` with some domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24632011",
   "metadata": {},
   "source": [
    "### 3.11.1 Instructions\n",
    "\n",
    "- Use `.dropna()` to drop missing values of the `cust_id` column in `banking` and store the results in `banking_fullid`.\n",
    "- Use `inv_amount` to compute the estimated account amounts for `banking_fullid` by setting the amounts equal to `inv_amount * 5`, and assign the results to `acct_imp`.\n",
    "- Impute the missing values of `acct_amount` in `banking_fullid` with the newly created `acct_imp` using `.fillna()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858717b",
   "metadata": {},
   "source": [
    "```python\n",
    "# Drop missing values of cust_id\n",
    "banking_fullid = banking.dropna(subset = ['cust_id'])\n",
    "\n",
    "# Compute estimated acct_amount\n",
    "acct_imp = banking_fullid['inv_amount']*5\n",
    "\n",
    "# Impute missing acct_amount with corresponding acct_imp\n",
    "banking_imputed = banking_fullid.fillna({'acct_amount':acct_imp})\n",
    "\n",
    "# Print number of missing values\n",
    "print(banking_imputed.isna().sum())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0159a",
   "metadata": {},
   "source": [
    "```\n",
    "cust_id             0\n",
    "acct_amount         0\n",
    "inv_amount          0\n",
    "account_opened      0\n",
    "last_transaction    0\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b493f",
   "metadata": {},
   "source": [
    "# 4 Record linkage\n",
    "\n",
    "Record linkage is a powerful technique used to merge multiple datasets together, used when values have typos or different spellings. In this chapter, you'll learn how to link records by calculating the similarity between strings—you’ll then use your new skills to join two restaurant review datasets into one clean master dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f521c",
   "metadata": {},
   "source": [
    "## 4.1 Comparing strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e7ee3",
   "metadata": {},
   "source": [
    "## 4.2 Minimum edit distance\n",
    "\n",
    "In the video exercise, you saw how minimum edit distance is used to identify how similar two strings are. As a reminder, minimum edit distance is the minimum number of steps needed to reach from ***String A*** to ***String B***, with the operations available being:\n",
    "\n",
    "- **Insertion** of a new character.\n",
    "- **Deletion** of an existing character.\n",
    "- **Substitution** of an existing character.\n",
    "- **Transposition** of two existing consecutive characters.\n",
    "\n",
    "*What is the minimum edit distance from* `'sign'` *to* `'sing'`, *and which operation(s) gets you there?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2349412",
   "metadata": {},
   "source": [
    "### 4.2.1 Answer the question\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "- [ ] 2 by substituting `'g'` with `'n'` and `'n'` with `'g'`.\n",
    "\n",
    "- [x] 1 by transposing `'g'` with `'n'`.\n",
    "\n",
    "- [ ] 1 by substituting `'g'` with `'n'`.\n",
    "\n",
    "- [ ] 2 by deleting `'g'` and inserting a new `'g'` at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c62848",
   "metadata": {},
   "source": [
    "## 4.3 The cutoff point\n",
    "\n",
    "In this exercise, and throughout this chapter, you'll be working with the `restaurants` DataFrame which has data on various restaurants. Your ultimate goal is to create a restaurant recommendation engine, but you need to first clean your data.\n",
    "\n",
    "This version of `restaurants` has been collected from many sources, where the `cuisine_type` column is riddled with typos, and should contain only `italian`, `american` and `asian` cuisine types. There are so many unique categories that remapping them manually isn't scalable, and it's best to use string similarity instead.\n",
    "\n",
    "Before doing so, you want to establish the cutoff point for the similarity score using the `thefuzz`'s `process.extract()` function by finding the similarity score of the most *distant* typo of each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559311a5",
   "metadata": {},
   "source": [
    "### 4.3.1 Instructions 1/2\n",
    "\n",
    "- Import `process` from `thefuzz`.\n",
    "- Store the unique `cuisine_type`s into `unique_types`.\n",
    "- Calculate the similarity of `'asian'`, `'american'`, and `'italian'` to all possible `cuisine_type`s using `process.extract()`, while returning all possible matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6814bb",
   "metadata": {},
   "source": [
    "```python\n",
    "# Import process from thefuzz\n",
    "from thefuzz import process\n",
    "\n",
    "# Store the unique values of cuisine_type in unique_types\n",
    "unique_types = restaurants['cuisine_type'].unique()\n",
    "\n",
    "# Calculate similarity of 'asian' to all values of unique_types\n",
    "print(process.extract('asian', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'american' to all values of unique_types\n",
    "print(process.extract('american', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'italian' to all values of unique_types\n",
    "print(process.extract('italian', unique_types, limit = len(unique_types)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5286f",
   "metadata": {},
   "source": [
    "```\n",
    "[('asian', 100), ('asiane', 91), ('asiann', 91), ('asiian', 91), ('asiaan', 91), ('asianne', 83), ('asiat', 80), ('italiann', 72), ('italiano', 72), ('italianne', 72), ('italian', 67), ('amurican', 62), ('american', 62), ('italiaan', 62), ('italiian', 62), ('itallian', 62), ('americann', 57), ('americano', 57), ('ameerican', 57), ('aamerican', 57), ('ameriican', 57), ('amerrican', 57), ('ammericann', 54), ('ameerrican', 54), ('ammereican', 54), ('america', 50), ('merican', 50), ('murican', 50), ('italien', 50), ('americen', 46), ('americin', 46), ('amerycan', 46), ('itali', 40)]\n",
    "[('american', 100), ('americann', 94), ('americano', 94), ('ameerican', 94), ('aamerican', 94), ('ameriican', 94), ('amerrican', 94), ('america', 93), ('merican', 93), ('ammericann', 89), ('ameerrican', 89), ('ammereican', 89), ('amurican', 88), ('americen', 88), ('americin', 88), ('amerycan', 88), ('murican', 80), ('asian', 62), ('asiane', 57), ('asiann', 57), ('asiian', 57), ('asiaan', 57), ('italian', 53), ('asianne', 53), ('italiann', 50), ('italiano', 50), ('italiaan', 50), ('italiian', 50), ('itallian', 50), ('italianne', 47), ('asiat', 46), ('itali', 40), ('italien', 40)]\n",
    "[('italian', 100), ('italiann', 93), ('italiano', 93), ('italiaan', 93), ('italiian', 93), ('itallian', 93), ('italianne', 88), ('italien', 86), ('itali', 83), ('asian', 67), ('asiane', 62), ('asiann', 62), ('asiian', 62), ('asiaan', 62), ('asianne', 57), ('amurican', 53), ('american', 53), ('americann', 50), ('asiat', 50), ('americano', 50), ('ameerican', 50), ('aamerican', 50), ('ameriican', 50), ('amerrican', 50), ('ammericann', 47), ('ameerrican', 47), ('ammereican', 47), ('america', 43), ('merican', 43), ('murican', 43), ('americen', 40), ('americin', 40), ('amerycan', 40)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e8709",
   "metadata": {},
   "source": [
    "### 4.3.2 Instructions 2/2\n",
    "\n",
    "### Question\n",
    "\n",
    "Take a look at the output, what do you think should be the similarity cutoff point when remapping categories?\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "- [x] 80\n",
    "\n",
    "- [ ] 70\n",
    "\n",
    "- [ ] 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703746eb",
   "metadata": {},
   "source": [
    "## 4.4 Remapping categories II\n",
    "\n",
    "In the last exercise, you determined that the distance cutoff point for remapping typos of `'american'`, `'asian'`, and `'italian'` cuisine types stored in the `cuisine_type` column should be 80.\n",
    "\n",
    "In this exercise, you're going to put it all together by finding matches with similarity scores equal to or higher than 80 by using `fuzywuzzy.process`'s `extract()` function, for each correct cuisine type, and replacing these matches with it. Remember, when comparing a string with an array of strings using `process.extract()`, the output is a list of tuples where each is formatted like:\n",
    "\n",
    "```python\n",
    "(closest match, similarity score, index of match)\n",
    "```\n",
    "\n",
    "The `restaurants` DataFrame is in your environment, and you have access to a `categories` list containing the correct cuisine types (`'italian'`, `'asian'`, and `'american'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13975105",
   "metadata": {},
   "source": [
    "### 4.4.1 Instructions 1/4\n",
    "\n",
    "- Return all of the unique values in the `cuisine_type` column of `restaurants`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8c0bf",
   "metadata": {},
   "source": [
    "```python\n",
    "# Inspect the unique values of the cuisine_type column\n",
    "print(restaurants['cuisine_type'].unique())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619d4aa",
   "metadata": {},
   "source": [
    "```\n",
    "['america' 'merican' 'amurican' 'americen' 'americann' 'asiane' 'itali'\n",
    " 'asiann' 'murican' 'italien' 'italian' 'asiat' 'american' 'americano'\n",
    " 'italiann' 'ameerican' 'asianne' 'italiano' 'americin' 'ammericann'\n",
    " 'amerycan' 'aamerican' 'ameriican' 'italiaan' 'asiian' 'asiaan'\n",
    " 'amerrican' 'ameerrican' 'ammereican' 'asian' 'italianne' 'italiian'\n",
    " 'itallian']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bbbb69",
   "metadata": {},
   "source": [
    "### 4.4.2 Instructions 2/4\n",
    "\n",
    "Okay! Looks like you will need to use some string matching to correct these misspellings!\n",
    "\n",
    "- As a first step, create a list of all possible `matches`, comparing `'italian'` with the restaurant types listed in the `cuisine_type` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14193adf",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = matches = process.extract('italian', restaurants['cuisine_type'], limit = len(restaurants))\n",
    "\n",
    "# Inspect the first 5 matches\n",
    "print(matches[0:5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1673bd7",
   "metadata": {},
   "source": [
    "```\n",
    "[('italian', 100, 11), ('italian', 100, 25), ('italian', 100, 41), ('italian', 100, 47), ('italian', 100, 49)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b06d7",
   "metadata": {},
   "source": [
    "### 4.4.3 Instructions 3/4\n",
    "\n",
    "Now you're getting somewhere! Now you can iterate through `matches` to reassign similar entries.\n",
    "\n",
    "- Within the `for` loop, use an `if` statement to check whether the similarity score in each `match` is greater than or equal to 80.\n",
    "- If it is, use `.loc` to select rows where `cuisine_type` in `restaurants` is *equal* to the current match (which is the first element of `match`), and reassign them to be `'italian'`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f4a4e",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = process.extract('italian', restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "# Iterate through the list of matches to italian\n",
    "for match in matches:\n",
    "  # Check whether the similarity score is greater than or equal to 80\n",
    "  if match[1] >= 80:\n",
    "    # Select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "    restaurants.loc[restaurants['cuisine_type'] == match[0], 'cuisine_type'] = 'italian'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba473435",
   "metadata": {},
   "source": [
    "### 4.4.4 Instructions 4/4\n",
    "\n",
    "Finally, you'll adapt your code to work with every restaurant type in `categories`.\n",
    "\n",
    "- Using the variable `cuisine` to iterate through `categories`, embed your code from the previous step in an outer `for` loop.\n",
    "- Inspect the final result. *This has been done for you.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b110d",
   "metadata": {},
   "source": [
    "```python\n",
    "# Iterate through categories\n",
    "for cuisine in categories:  \n",
    "  # Create a list of matches, comparing cuisine with the cuisine_type column\n",
    "  matches = process.extract(cuisine, restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "  # Iterate through the list of matches\n",
    "  for match in matches:\n",
    "     # Check whether the similarity score is greater than or equal to 80\n",
    "    if match[1] >= 80:\n",
    "      # If it is, select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "      restaurants.loc[restaurants['cuisine_type'] == match[0]] = cuisine\n",
    "\n",
    "# Inspect the final result\n",
    "print(restaurants['cuisine_type'].unique())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d1c2d",
   "metadata": {},
   "source": [
    "```\n",
    "['american' 'asian' 'italian']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040613e",
   "metadata": {},
   "source": [
    "## 4.5 Generating pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b1a10",
   "metadata": {},
   "source": [
    "## 4.6 To link or not to link?\n",
    "\n",
    "Similar to joins, record linkage is the act of linking data from different sources regarding the same entity. But unlike joins, record linkage does not require exact matches between different pairs of data, and instead can find close matches using string similarity. This is why record linkage is effective when there are no common unique keys between the data sources you can rely upon when linking data sources such as a unique identifier.\n",
    "\n",
    "In this exercise, you will classify each card whether it is a traditional join problem, or a record linkage one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8fee5",
   "metadata": {},
   "source": [
    "### 4.6.1 Instructions\n",
    "\n",
    "- Classify each card into a problem that requires record linkage or regular joins.\n",
    "\n",
    "| Record linkage                                                                                                                              | Regular joins                                                                                                                    |\n",
    "|:-------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| Merging two basketball DataFrames, with columns `team_A`, `team_B`, and `time` and differently formatted team names between each DataFrame. | Two basketball DataFrames with a common unique identifier per game.                                                              |\n",
    "| Using an `address` column to join two DataFrames, with the address in each DataFrame being formatted slightly differntly.                   | Consolidating two DataFrames containing details on DataCamp courses, with each DataCamp course having its own unique identifier. |\n",
    "| Two customer Dataframes containing names and address, one with a unique identifier per customer, one without.                               |                                                                                                                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff31d6a",
   "metadata": {},
   "source": [
    "## 4.7 Pairs of restaurants\n",
    "\n",
    "In the last lesson, you cleaned the `restaurants` dataset to make it ready for building a restaurants recommendation engine. You have a new DataFrame named `restaurants_new` with new restaurants to train your model on, that's been scraped from a new data source.\n",
    "\n",
    "You've already cleaned the `cuisine_type` and `city` columns using the techniques learned throughout the course. However you saw duplicates with typos in restaurants names that require record linkage instead of joins with `restaurants`.\n",
    "\n",
    "In this exercise, you will perform the first step in record linkage and generate possible pairs of rows between `restaurants` and `restaurants_new`. Both DataFrames, `pandas` and `recordlinkage` are in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa2cfa",
   "metadata": {},
   "source": [
    "### 4.7.1 Instructions 1/2\n",
    "\n",
    "- Instantiate an indexing object by using the `Index()` function from `recordlinkage`.\n",
    "- Block your pairing on `cuisine_type` by using `indexer`'s' `.block()` method.\n",
    "- Generate pairs by indexing `restaurants` and `restaurants_new` in that order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da30e8",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create an indexer and object and find possible pairs\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Block pairing on cuisine_type\n",
    "indexer.block('cuisine_type')\n",
    "\n",
    "# Generate pairs\n",
    "pairs = indexer.index(restaurants, restaurants_new)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1b8bd",
   "metadata": {},
   "source": [
    "### 4.7.2 Instructions 2/2\n",
    "\n",
    "### Question\n",
    "\n",
    "Now that you've generated your pairs, you've achieved the first step of record linkage. What are the steps remaining to link both restaurants DataFrames, and in what order?\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "- [x] Compare between columns, score the comparism, then link the DataFrames.\n",
    "\n",
    "- [ ] Clean the data, Compare between columns, link the DataFrames, then score the comparism\n",
    "\n",
    "- [ ] Clean the data, Compare between columns, score the comparism, then link the DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef1afd",
   "metadata": {},
   "source": [
    "## 4.8 Similar restaurants\n",
    "\n",
    "In the last exercise, you generated pairs between `restaurants` and `restaurants_new` in an effort to cleanly merge both DataFrames using record linkage.\n",
    "\n",
    "When performing record linkage, there are different types of matching you can perform between different columns of your DataFrames, including exact matches, string similarities, and more.\n",
    "\n",
    "Now that your pairs have been generated and stored in `pairs`, you will find exact matches in the `city` and `cuisine_type` columns between each pair, and similar strings for each pair in the `rest_name` column. Both DataFrames, `pandas` and `recordlinkage` are in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedbc75",
   "metadata": {},
   "source": [
    "### 4.8.1 Instructions 1/4\n",
    "\n",
    "- Instantiate a comparison object using the `recordlinkage.Compare()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca8e70",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de026427",
   "metadata": {},
   "source": [
    "### 4.8.2 Instructions 2/4\n",
    "\n",
    "- Use the appropriate `comp_cl` method to find exact matches between the `city` and `cuisine_type` columns of both DataFrames.\n",
    "- Use the appropriate `comp_cl` method to find similar strings with a `0.8` similarity threshold in the `rest_name` column of both DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47d9ad",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches on city, cuisine_types \n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('cuisine_type', 'cuisine_type', label = 'cuisine_type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('rest_name', 'rest_name', label='name', threshold=0.8) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa21d0",
   "metadata": {},
   "source": [
    "```\n",
    "<Compare>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4e8d1",
   "metadata": {},
   "source": [
    "### 4.8.3 Instructions 3/4\n",
    "\n",
    "- Compute the comparison of the pairs by using the `.compute()` method of `comp_cl`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd597c7b",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches on city, cuisine_types - \n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('cuisine_type', 'cuisine_type', label='cuisine_type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('rest_name', 'rest_name', label='name', threshold = 0.8) \n",
    "\n",
    "# Get potential matches and print\n",
    "potential_matches = comp_cl.compute(pairs, restaurants, restaurants_new)\n",
    "print(potential_matches)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f18d2c",
   "metadata": {},
   "source": [
    "```\n",
    "        city  cuisine_type  name\n",
    "0   0      0             1   0.0\n",
    "    1      0             1   0.0\n",
    "    7      0             1   0.0\n",
    "    12     0             1   0.0\n",
    "    13     0             1   0.0\n",
    "...      ...           ...   ...\n",
    "40  18     0             1   0.0\n",
    "281 18     0             1   0.0\n",
    "288 18     0             1   0.0\n",
    "302 18     0             1   0.0\n",
    "308 18     0             1   0.0\n",
    "\n",
    "[3631 rows x 3 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32656a",
   "metadata": {},
   "source": [
    "## 4.8.4 Instructions 4/4\n",
    "\n",
    "### Question\n",
    "\n",
    "Print out `potential_matches`, the columns are the columns being compared, with values being 1 for a match, and 0 for not a match for each pair of rows in your DataFrames. To find potential matches, you need to find rows with more than matching value in a column. You can find them with\n",
    "\n",
    "```python\n",
    "potential_matches[potential_matches.sum(axis = 1) >= n]\n",
    "```\n",
    "\n",
    "Where `n` is the minimum number of columns you want matching to ensure a proper duplicate find, what do you think should the value of `n` be?\n",
    "\n",
    "- [x] 3 because I need to have matches in all my columns\n",
    "\n",
    "- [ ] 2 because matching on any of the 2 columns or more is enough to find potential duplicates.\n",
    "\n",
    "- [ ] 1 because matching on just 1 column like the restaurant name is enough to find potential duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c47f256",
   "metadata": {},
   "source": [
    "## 4.9 Linking DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ad249",
   "metadata": {},
   "source": [
    "## 4.10 Getting the right index\n",
    "\n",
    "Here's a DataFrame named `matches` containing potential matches between two DataFrames, `users_1` and `users_2`. Each DataFrame's row indices is stored in `uid_1` and `uid_2` respectively.\n",
    "\n",
    "```\n",
    "             first_name  address_1  address_2  marriage_status  date_of_birth\n",
    "uid_1 uid_2                                                                  \n",
    "0     3              1          1          1                1              0\n",
    "     ...            ...         ...        ...              ...            ...\n",
    "     ...            ...         ...        ...              ...            ...\n",
    "1     3              1          1          1                1              0\n",
    "     ...            ...         ...        ...              ...            ...\n",
    "     ...            ...         ...        ...              ...            ...\n",
    "```\n",
    "\n",
    "How do you extract all values of the `uid_1` index column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f0ede",
   "metadata": {},
   "source": [
    "### 4.10.1 Answer the question\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "- [ ] `matches.index.get_level_values(0)`\n",
    "\n",
    "- [ ] `matches.index.get_level_values(1)`\n",
    "\n",
    "- [ ] `matches.index.get_level_values('uid_1')`\n",
    "\n",
    "- [x] Both 1 and 3 are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa94c0",
   "metadata": {},
   "source": [
    "## 4.11 Linking them together!\n",
    "\n",
    "In the last lesson, you've finished the bulk of the work on your effort to link `restaurants` and `restaurants_new`. You've generated the different pairs of potentially matching rows, searched for exact matches between the `cuisine_type` and `city` columns, but compared for similar strings in the `rest_name` column. You stored the DataFrame containing the scores in `potential_matches`.\n",
    "\n",
    "Now it's finally time to link both DataFrames. You will do so by first extracting all row indices of `restaurants_new` that are matching across the columns mentioned above from `potential_matches`. Then you will subset `restaurants_new` on these indices, then append the non-duplicate values to `restaurants`. All DataFrames are in your environment, alongside `pandas` imported as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd51c1",
   "metadata": {},
   "source": [
    "### 4.11.1 Instructions\n",
    "\n",
    "- Isolate instances of `potential_matches` where the row sum is above or equal to 3 by using the `.sum()` method.\n",
    "- Extract the second column index from `matches`, which represents row indices of matching record from `restaurants_new` by using the `.get_level_values()` method.\n",
    "- Subset `restaurants_new` for rows that are not in `matching_indices`.\n",
    "- Append `non_dup` to `restaurants`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8676f",
   "metadata": {},
   "source": [
    "```python\n",
    "# Isolate potential matches with row sum >=3\n",
    "matches = potential_matches[potential_matches.sum(axis = 1) >= 3]\n",
    "\n",
    "# Get values of second column index of matches\n",
    "matching_indices = matches.index.get_level_values(1)\n",
    "\n",
    "# Subset restaurants_new based on non-duplicate values\n",
    "non_dup = restaurants_new[~restaurants_new.index.isin(matching_indices)]\n",
    "\n",
    "# Append non_dup to restaurants\n",
    "full_restaurants = restaurants.append(non_dup)\n",
    "print(full_restaurants)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7366a6",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "                    rest_name                  rest_addr               city       phone cuisine_type\n",
    "0   arnie morton's of chicago   435 s. la cienega blv .         los angeles  3102461501     american\n",
    "1          art's delicatessen       12224 ventura blvd.         studio city  8187621221     american\n",
    "2                   campanile       624 s. la brea ave.         los angeles  2139381447     american\n",
    "3                       fenix    8358 sunset blvd. west           hollywood  2138486677     american\n",
    "4          grill on the alley           9560 dayton way         los angeles  3102760615     american\n",
    "..                        ...                        ...                ...         ...          ...\n",
    "76                        don        1136 westwood blvd.           westwood  3102091422      italian\n",
    "77                      feast        1949 westwood blvd.            west la  3104750400      chinese\n",
    "78                   mulberry        17040 ventura blvd.             encino  8189068881        pizza\n",
    "80                    jiraffe      502 santa monica blvd       santa monica  3109176671  californian\n",
    "81                   martha's  22nd street grill 25 22nd  st. hermosa beach  3103767786     american\n",
    "\n",
    "[396 rows x 5 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eacfb8a",
   "metadata": {},
   "source": [
    "## 4.12 Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
